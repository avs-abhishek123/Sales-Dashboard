import dateutil.utils
from flask`` import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import jsonimport dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
00000000000000000000000000000000000000000000000000000000000000000000def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
    #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(sta   tus_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(fina    l.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)

33.
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@ap     p .route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 import dateutil.utils
from flask import Flask, request, jsonify, render_template, redirect
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text
import os, time
import utility
import json
import pandas as pd
import datetime
import sys
import math
import random

app = Flask(__name__)

#oxygen-aurora2-cluster.cluster-cladr7eisf0t.us-east-1.rds.amazonaws.com

app.config["SQLALCHEMY_DATABASE_URI"] = "mysql://superset:45zCl40G7cWn@oxygen-aurora2-cluster.cluster-cladr7eisf0t." \
                                        "us-east-1.rds.amazonaws.com/superset_views"
db = SQLAlchemy(app)
db.create_all()
# Test


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/ping')
def ping():
    return 'i am here pong'


def master_module():
    # call back

    # one week old

    # onehour_call(batchsize, city, state, carrier_type):

    # one week old ENDS HERE



    # three months old
        # threemonths_notInterested(batchsize, city, state, carrier_type)
    # three months old ends here

    # top category
             # top_cat_records(city, state, batchsize, top_cat, carrier_type='mix' )
    # top category ends here

    #random records

            # random_records_fun(batchsize, hour, day, today, batchID, city, state, carrier_type='mix', flag = 1)

    #random records ENDS HERE


    # insert_Temp_Outbound_batches(finalDF, hour, day, today, batchID)

    pass


# {'batchids': [1,2,3]} EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/delete-batch', methods=['POST'])
def del_batchAPI():
    values = request.json['batchids']
    string_ints = [str(x) for x in values]
    s = ",".join(map("'{0}'".format, string_ints))
    db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
    db.session.commit()
    return '200'
    

# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingthis')
# def call_back(hour, day, today, batchID):
# def call_back(batchsize):
def call_back(hour, day, today, batchID, batchsize, city = None, state = None, county = None):
    # batchsize = 100
    params  = request.get_json()
    call_type = 'CALLBACK'
    callback_day = 0
    callback_hour = 0
    records = 0

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    query = ('SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type')
    params = {'call_type' : call_type}
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file = sys.stderr)
    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1

    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])

    # query = "select r.master_id from superset_views.call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Callback' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = hour(now()) and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')"\
    #         f"order by r.creationtime desc {limitbatch}"
    # query_callback = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus = :call_type) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_callback = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
                     f"WHERE (r.status = 'Callback') AND ((r.city = :city) AND (r.state = :state) AND (r.county = :county)) "\
                     f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
                     f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
                     f"OR (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                     f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
                     f"ORDER BY r.creationtime"
    params = {'city': city, 'state': state, 'county': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': limitbatch}
    #print(query_callback, file=sys.stderr)
    data = db.session.execute(text(query_callback), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
    print(len(data), file=sys.stderr)
    print(data, file=sys.stderr)

    # data = data.to_json()
    # return (data)
    if len(data) != 0:
        len_gth = len(data)
        for i in range(0, len_gth):
            # if len(data.iloc[i]['T1'])>0:
            mid = data.iloc[i]['master_id']
            query = "SELECT id, category, rootcategory, parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE id = :mid"
            params = {'mid' : mid}
            record = db.session.execute(text(query), params)
            record = convert_json(record)
            record = pd.json_normalize(record)
            # print(record, file=sys.stderr)
            record.drop_duplicates(subset=['id'], keep="first", inplace=True)
            callback_df = callback_df.append(record, ignore_index=True)
            # print(callback_df, file=sys.stderr)
            # return str(callback_df)
            # else:
        callback_df['call_type'] = 'CALLBACK'

        records = insert_Temp_Outbound_batches(callback_df, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return str(0)
    # print(callback_df,file = sys.stderr)

    return str(records)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing2')
#def callattempted_notconnected():
def callattempted_notconnected(hour, day, today, batchID, batchsize,  city=None, state=None, county=None):
    print("I am Inside Call Attempted1", file=sys.stderr)
    # hour = 10
    # day = 'Monday'
    # today = datetime.datetime.now()
    # batchID = 10
    # batchsize = 20
    # city=None
    # state=None
    # county=None

    params = request.get_json()
    # {
    #       "call_type" : request.json['CALLATTEMPTED_NOTCONNECTED']
    # }
    call_type = 'CALLATTEMPTED_NOTCONNECTED'
    call_type= call_type.upper()
    flag = 1

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted2", file=sys.stderr)
    #print(f"{query}", file=sys.stderr)
    data = db.session.execute(text(query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            # print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            pass

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            pass
    else:
        # print("here i am 5", file=sys.stderr)
        callback_day = 1
        callback_hour = 1
    
    # return str(callback_hour)
    # query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp " \
    #         f"WHERE (length(LastContactDate)>1) AND (hour(LastContactDate) <= hour(now()-INTERVAL (:callback_hour) hour)) " \
    #         f"AND (date(LastContactDate) = date(now()-INTERVAL (:callback_day) day)) " \
    #         f"AND ((mp.city = :city)  AND (mp.state = :state)  AND (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) " \
    #         f"AND (contactphonestatus is NULL) AND (sentiment is NULL) AND "\
    #         f"id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type) (:limitbatch)"
    query_notconn = "SELECT id, category, ParentCategory, RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
              f"WHERE (LastContactDate is NULL) AND (contactphonestatus is NULL) "\
              f"AND ((mp.city = :city)  AND (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0 AND ValueScore !=50) "\
              f"AND (id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
              f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats)) "
    params = {'city': city, 'state': state, 'county': county, 'call_type': call_type}
    #print(query_notconn, file=sys.stderr)
    data = db.session.execute(text(query_notconn), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    app.logger.info(params)
    print(data, file = sys.stderr)
    # return jsonify(data)
    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0
    if flag == 1:
        data["call_type"] = call_type
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
# def notinterested(batchsize, city, state, carrier_type):
def notinterested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):
    # city = 'Los Angeles'
    # state = 'CA'
    today = datetime.datetime.now()
    callback_day = 0
    callback_hour = 0
    # batchsize = 100
    flag = 1
    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    # params = {
    #       'call_type' : request.json['notinterested']
    # }
    call_type = "notinterested"
    #query = f"select days, hours from superset_views.call_parameters where call_type =  \'{call_type}\'"
    query = 'SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type'
    params = {'call_type' : call_type}
    print("I am Inside Call Attempted6", file=sys.stderr)
    data = db.session.execute((query), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    print(type(data.iloc[0]['days']), file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            print("here i am 1", file=sys.stderr)
            callback_day = data.iloc[0]['days']
        else:
            # print("here i am 2", file=sys.stderr)
            callback_day = 1

        if isinstance(data.iloc[0]['hours'], str):
            # print("here i am 3", file=sys.stderr)
            callback_hour = data.iloc[0]['hours']
        else:
            # print("here i am 4", file=sys.stderr)
            callback_hour = 0
    else:
        print("here i am 5", file=sys.stderr)
        callback_day = 90
        callback_hour = 0
    #select id, category, if (length(city)>0,city,County ) as city, state FROM MasterProvider for using the city or county
    # query = "SELECT id, category ,ParentCategory , RootCategory, LastContactDate, ContactPhoneStatus FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
    #         f"WHERE (ContactPhoneStatus = :call_type) AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) " \
    #         f"AND (LastContactDate = now() - interval (:callback_day) day) AND (hour(LastContactDate) <= hour(now() - interval (:callback_hour) hour)) " \
    #         f"AND category NOT IN (SELECT keyword FROM superset_views.excluded_cats) AND  " \
    #         f"id NOT IN (SELECT master_id FROM Outbound_batches WHERE batch_type = :call_type)" \
    #         f" (:limitbatch)"
    query_notint = "SELECT id, category ,ParentCategory , RootCategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider mp "\
                   f"WHERE ((LastContactDate is NOT NULL) AND  hour(LastContactDate) > hour(now() - INTERVAL (:callback_hour) hour)) "\
                   f"AND (ContactPhoneStatus is NOT NULL) AND (date(LastContactDate) = date(now() - interval (:callback_day) day)) "\
                   f"AND ((mp.city = :city) and (mp.state = :state) and (mp.county = :county)) AND (ValueScore !=0  AND ValueScore != 50) "\
                   f"AND (mp.id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
                   f"AND (category NOT IN (SELECT keyword FROM superset_views.excluded_cats))"
    params = {'callback_hour': callback_hour, 'callback_day': callback_day, 'city': city, 'state': state, 'county': county, 'call_type': call_type, 'limitbatch': batchsize}
    print("inside not interested ", file=sys.stderr)

    data = db.session.execute(text(query_notint), params)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
    # return jsonify(data)

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        len_data = len(data)
        if len_data > 0:
            if len(data) >= batchsize:
                data = data[0:batchsize]
            else:
                data = data[0:len_data]
        else:
            flag = 0
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = "NotInterested"
        # hour = 'NULL'
        # batchID = 'NULL'
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
        return records
    else:
        return 0


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing33')
def interested(hour, batchID, day,  batchsize,  city=None, state=None, county=None):

    # city = 'Los Angeles'
    # state = 'CA'
    call_type = 'interested'
    today = datetime.datetime.now()
    #batchsize = 100
    # callback_day = 4
    # callback_hour = 1
    #batchsize = 50

    andcity = ""
    if city:
        andcity = f"and (city = \'{city}\')"
    andstate = ""
    if state:
        andstate = f"and (state = \'{state}\')"
    andcounty = ""
    if county:
        andcounty = f"and (county = \'{county}\')"

    limitbatch=""
    if batchsize:
        limitbatch = f"LIMIT {batchsize}"

    callback_day = 0
    callback_hour = 0
    flag = 1
    query_int = "SELECT days, hours FROM superset_views.call_parameters WHERE call_type = :call_type"
    params = {'call_type' : call_type}
    #print(query_int, file = sys.stderr)
    data = db.session.execute(text(query_int), params)
    data = convert_json(data)
    data = pd.json_normalize(data)

    query_time = "SELECT extract(hour from creationtime)"\
                    " FROM superset_views.call_category_raw"
    t1= db.session.execute(text(query_time))
    t1 = convert_json(t1)
    t1 = pd.json_normalize(t1)
    print(t1,file=sys.stderr)

    if len(data) > 0:
        if isinstance(data.iloc[0]['days'], str):
            callback_day = data.iloc[0]['days']
        else:
            pass

        if isinstance(data.iloc[0]['hours'], str):
            callback_hour = data.iloc[0]['hours']
        else:
            pass
    else:
        callback_day = 7
        callback_hour = 1
    
    print(callback_hour, file = sys.stderr)
    print(call_type, file = sys.stderr)
    #return str(callback_day)

    params = request.get_json()
    callback_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    #check this query with sirajul
    # query = "select h.T1, r.creationtime, r.master_id from call_category_raw r " \
    #         "JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"where r.status = 'Interested' {andcity}  {andstate}  {andcounty}" \
    #         f" and ((hour(h.t1) = {hour} and date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL {callback_day} Day) = date(r.creationtime) and (hour((r.creationtime)) <= hour(now()-INTERVAL {callback_hour} hour))))" \
    #         f"and r.master_id NOT IN (select master_id from superset_views.Outbound_batches where batch_type = \'{call_type}\')" \
    #         f" order by r.creationtime desc {limitbatch}"
    # query = "SELECT h.T1, r.creationtime, r.master_id FROM call_category_raw r JOIN oxygen_history.oxygen_history_2021_08_25 h ON h.PK = r.source_pk " \
    #         f"WHERE r.status = 'Interested' AND ((:andcity) and (:andstate) and (:andcounty))" \
    #         f" AND ((hour(h.t1) = (:hour) AND date(h.t1) = date(now())) " \
    #         f"OR (date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime) AND (hour((r.creationtime)) <= hour(now()-INTERVAL (:callback_hour) hour)))) " \
    #         f"AND r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = (:call_type))" \
    #         f" ORDER BY r.creationtime desc"
    #query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
    #            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) and (r.county = :andcounty)) "\
    #            f"AND ((date(t1) = date(now()) OR (hour(t1) = :hour)) "\
    #            f"OR ((date(now()-INTERVAL (:callback_day) Day) = date(r.creationtime)) AND (hour(r.creationtime) <= hour(now()-INTERVAL (:callback_hour) hour)))) "\
    #            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
    #            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
    #            f"ORDER BY r.creationtime"

    # Use Historical_basis table from superset_views

    query_int = "SELECT r.master_id, r.category, r.ParentCategory, r.RootCategory FROM superset_views.call_category_raw r "\
            f"WHERE (r.status = 'interested') AND ((r.city = :andcity) and (r.state = :andstate) ) "\
            f"AND (:t1 = :hour)) "\
            f"AND (r.master_id NOT IN (SELECT master_id FROM superset_views.Outbound_batches WHERE batch_type = :call_type)) "\
            f"AND r.category NOT IN (SELECT keyword FROM superset_views.excluded_cats) "\
            f"ORDER BY r.creationtime"


    params = {'andcity': city, 'andstate': state, 'andcounty': county, 'hour': hour, 'callback_day': callback_day, 'callback_hour': callback_hour, 'call_type': call_type, 'limitbatch': batchsize}
    print("Inside interested", file=sys.stderr)
    print('status',file=sys.stderr)
    print(query_int,file=sys.stderr)
    print(params,file=sys.stderr)
    data = db.session.execute(text(query_int), params)
    #print(data, file=sys.stderr)
    data = convert_json(data)
    data = pd.json_normalize(data)
    print(data, file=sys.stderr)
   

    if isinstance(data, pd.DataFrame):
        data.drop_duplicates(subset=['master_id'], keep="first", inplace=True)
        if len(data) != 0:
            len_gth = len(data)
            for i in range(0, len_gth):
                # if len(data.iloc[i]['T1'])>0:
                mid = data.iloc[i]['master_id']
                query = "SELECT id, category, rootcategory, parentcategory FROM 'sumithapauroramysql20181211-cluster-LotusDirectory'.MasterProvider WHERE id = :mid"
                record = db.session.execute(query)
                record = convert_json(record)
                record = pd.json_normalize(record)
                # print(record, file=sys.stderr)
                record.drop_duplicates(subset=['id'], keep="first", inplace=True)
                callback_df = callback_df.append(record, ignore_index=True)
                print(callback_df, file=sys.stderr)
                # return str(callback_df)
                # else:
        else:
            flag = 0
    # print(callback_df,file = sys.stderr)
    else:
        flag = 0

    if flag == 1:
        data["call_type"] = f"{call_type}"
        # select dayname(now()) return day of week in string
        print(data, file=sys.stderr)
        records = insert_Temp_Outbound_batches(data, hour, day, today, batchID) #uncomment this and resolve the error
    else:
        return 0

    return str(records)


def randomness(left_categories, batchsize):
# def ranmom():
#     batchsize = 100
#     left_categories = ['ambulance service', 'car inspection service', 'jeweler', 'movers', 'electrician fish tape', 'automotive & vehicle', 'computer store',
#                        'fitness clubs', 'transportation service', 'hair color', 'electricians', 'dentists referral service', 'construction services']

    final_df = pd.DataFrame()
    backlog = 0

    left_cat_len = len(left_categories)
    if left_cat_len == 0:
        return 0

    avg = math.floor(batchsize / left_cat_len)
    rem = batchsize % left_cat_len

    cat_dict = {}
    for cat in left_categories:
        cat_dict[cat] = avg

    if rem > 0:
        for cat in left_categories:
            if rem == 0:
                break
            cat_dict[cat] = cat_dict[cat] + 1
            rem = rem - 1

    cat_dict = {key: val for key, val in cat_dict.items() if val != 0}

    for category in cat_dict:
        temp_df = pd.DataFrame()
        lim_it = cat_dict[category] + backlog
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(lim_it)

        query = 'SELECT id, rootcategory, parentcategory, category, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
                f'WHERE (City = "Los Angeles" and state = "CA" ) AND verifiedphone IS NOT NULL AND (ValueScore != 0 and ValueScore != 50) AND length(category)>1 ' \
                f'AND ((ContactPhoneStatus IS NULL AND lastcontactDate IS NULL) OR (ContactPhoneStatus is null AND lastcontactDate < now() - interval 1 month)) ' \
                f'AND category = :category  AND  LIMIT = :lim_it'

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        if len(category_wise_data) != lim_it:
            backlog = lim_it - len(category_wise_data)
        else:
            backlog = 0

        if len(category_wise_data) > 0:
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            final_df = final_df.append(temp_df, ignore_index=True)
            del temp_df

    final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
    final_df['batch_type'] = 'Random'
    return final_df

    #     rows = list(category_wise_data.shape)
    #     rows = rows[0]
    #     random_rec = random_rec + rows
    #     if rows > 1:
    #         id_list = category_wise_data['id']
    #         temp_df['id'] = category_wise_data['id']
    #         temp_df['category'] = category_wise_data['category']
    #         temp_df['rootcategory'] = category_wise_data['rootcategory']
    #         temp_df['parentcategory'] = category_wise_data['parentcategory']
    #         id_list = id_list.to_list()
    #         current_batch_size = len(id_list)
    #         if current_batch_size > batchsize:
    #             id_list = id_list[0:batchsize]
    #             temp_df = temp_df[0:batchsize]
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             final_id.extend(id_list)
    #             flag = 0
    #         else:
    #             final_id.extend(id_list)
    #             final_df = final_df.append(temp_df, ignore_index= True)
    #             batchsize = batchsize-current_batch_size
    #             del temp_df
    #             del category_wise_data
    #     else:
    #         pass
    #
    #     if flag == 0:
    #         break
    #     for row in range(0, rows):
    #         # print("HERE 4", file=sys.stderr)
    #         mid = final.iloc[row]['id']
    #         cate_gory = final.iloc[row]['category']
    #         parent_category = final.iloc[row]['parentcategory']
    #         root_category = final.iloc[row]['rootcategory']
    #         # db.session.execute(text(('INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
    #         #          ' values ('+ '\'' +str(hour) + '\'' + ','+ '\'' + str(day) + '\'' +','  + '\'' + str(cate_gory) + '\'' +',' +'\'' + str(parent_category)+'\''+','+'\''+ str(root_category) +'\''+',' +'\''+ str(mid) +'\''+','+'\''+str(today) +'\'' +','+'\''+ str(batchID) +'\''+')')))
    #         record_inserted = record_inserted + 1
    #     db.session.commit()
    #
    # print(str(record_inserted)+" Record Inserted into outbound_batch table", file = sys.stderr)
    # return random_rec


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide')
def hello():
    return 'Hello Simplia From: ' + utility.getUrl('/' + os.environ['APP_NAME'] + '/System/ServerSide')


def time_checker(week_day, ti_me):  # Working Fine
    params = request.get_json() 
    #{
    #          'week_day' : request.json['week_day'],
    #          'ti_me'    : request.json['hour']
    # }
    query_time = (f"SELECT status FROM Time_rules WHERE ((weekday = :week_day) AND (time = :ti_me))")
    params = {'week_day': week_day, 'ti_me': ti_me}
   000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 #query_time = "select status from Time_rules where weekday = " + "\'" + str(week_day) + "\'" + " and time = " + str(ti_me)
    time_query = text(query_time)
    time_query = db.session.execute((time_query), params)
    result = convert_json(time_query)
    if len(result) > 0:
        status = [f['status'] for f in result]
        status = status[0]
        return status
    else:
        return -1


def city_checker(table_name, state, city):
    params = request.get_json()
    # {
    #       "table_name" : request.json['table_name'],
    #       "state"    : request.json['state'],
    #       "city"    : request.json['city']
    # }
    query_city = ("SELECT id FROM (table_name = :table_name) WHERE ((city = :city) AND (state = :state))", params)
    city_query = text(query_city)
    city_query = db.session.execute(city_query)
    result = convert_json(city_query)
    if len(result) > 0:
        return 1
    else:
        return -1


# db.session.execute(text(f'DELETE FROM superset_views.Outbound_batches where Batch_id in ({s})'))
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testing7')
def testing_web():
    city = None
    state = None
    county = "CA"
    callback_day = 4
    callback_hour = 1
    batchsize = 50
    andcity = ""
    if city:
        andcity = f"And city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"

    query = "SELECT id, category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider " \
            f"WHERE ContactPhoneStatus = 'NotInterested'  AND ((city = :city)  AND (state = :state)  AND (county = :county)) limit 10"

    data = db.session.execute(text(query))
    data = convert_json(data)
    # data = pd.json_normalize(data)
    return jsonify(data)


def random_records_fun(batchsize, hour, day, today, batchID, county, city, state, carrier_type='mix', flag = 1):
    print("I am at random_records_fun ",file=sys.stderr)
    params = request.get_json() 
    random_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    record_per_cat = 20
    len_random_records = 0
    used_categories = []
    query = 'SELECT min(id),max(id) FROM superset_views.included_cats '
    historical_basis1 = db.session.execute(text(query))
    historical_basis1 = convert_json(historical_basis1)
    historical_basis1 = pd.json_normalize(historical_basis1)

    in_cat_minPk = historical_basis1.iloc[0][0]
    in_cat_maxPk = historical_basis1.iloc[0][1]
    #carrier_type code
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"


    while (len_random_records < batchsize):
        #params = request.get_json()
        temp_df = pd.DataFrame()
        n = random.randint(in_cat_minPk, in_cat_maxPk)
        query = 'SELECT keyword FROM superset_views.included_cats where id = ' + str(n)
        historical_basis = db.session.execute(text(query))
        historical_basis = convert_json(historical_basis)
        historical_basis = pd.json_normalize(historical_basis)
        if len(historical_basis) > 0 :
            category = historical_basis.iloc[0][0]  # selected random category is in category
            # category = category.replace('\'', '') removed this may code crash because of abc's type categories
            if category in used_categories:
                continue
            else:
                used_categories.append(category)

            # category = "women's clothing stores"

            # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
            #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
            #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
            #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
            #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(record_per_cat)
            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(record_per_cat)

            # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
            #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
            #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
            #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(record_per_cat)
                                
            # query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) AND ((mp.city = \'{city}\') and (mp.state = \'{state}\') and (mp.county = \'{county}\')) " \
            #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
            #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \"{category}\") ORDER BY mp.id LIMIT {record_per_cat}"
            #         #f"VALUES ('andcity': city, 'andstate': state, 'andcounty': county, 'carriertype': carriertype, 'category': category, 'record_per_cat':record_per_cat)"))

            #query_random = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
            #            f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) " \
            #            f"AND ((mp.city = :city) AND (mp.state = :state) AND (mp.county = :county)) " \
            #            f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
            #            f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
            #            f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH) " \
            #            f"AND (mp.carriertype IN (carriertype)) AND (mp.Category = ob.category) ORDER BY mp.id LIMIT :record_per_cat "
            


            query_random = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                         f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype}))   LIMIT :record_per_cat "


            params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'record_per_cat' : record_per_cat}
            mp_data = db.session.execute(text(query_random), params)
            mp_data = convert_json(mp_data)
            mp_data = pd.json_normalize(mp_data)
            print("its mp_data", file = sys.stderr)
            print(mp_data, file=sys.stderr)

            if isinstance(mp_data, pd.DataFrame):  # do we have records from top categories if yes than
                if len(mp_data) >  0:
                    temp_df['id'] = mp_data['id']
                    temp_df['category'] = mp_data['category']
                    temp_df['rootcategory'] = mp_data['rootcategory']
                    temp_df['parentcategory'] = mp_data['parentcategory']
                    temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                    random_df = random_df.append(temp_df, ignore_index=True)
                    random_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                    len_random_records = len(random_df)
                    del temp_df
                    del mp_data

            if len(random_df)==0: 
                return random_df       

    random_df = random_df[0:batchsize]
    # today = datetime.datetime.now()
    # print("i am at random df", file = sys.stderr)
    # print(random_df, file=sys.stderr)
    if flag == 1:
        random_df['call_type'] = 'Random Category'
        s = insert_Temp_Outbound_batches(random_df, hour, day, today, batchID)
        del random_df
        print("i am at random cat its returning s = "+str(s),file=sys.stderr)
        return s
    else:
        random_df['call_type'] = 'Random Category'
        print("I am exiting random_records_fun ",file=sys.stderr)
        return random_df
    # print(random_df[['category','parentcategory']],file=sys.stderr)
    # random_df = random_df.to_json()
    # print(random_df,file=sys.stderr)


#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/topcat')
def top_cat_records(county, city, state, batchsize, top_cat, carrier_type):
    
    print("i am at top cat records",file=sys.stderr)
 
    
    carrier_type = carrier_type.lower()
    if carrier_type == 'wireless':
        carriertype = "'mobile'"
    elif carrier_type == 'wireline':
        carriertype = "'landline', 'voip'"
    else:
        carriertype = "'landline', 'mobile', 'voip'"

    

    andcity = ""
    if city:
        andcity = f"and city = \'{city}\'"
    andstate = ""
    if state:
        andstate = f"and state = \'{state}\'"
    andcounty = ""
    if county:
        andcounty = f"and county = \'{county}\'"
    
    #andcategori = ""
    #if categori:
    #    andcategori = f"and categori = \'{categori}\'"
    
    #andparent_category = ""
    #if parent_category:
    #    andparent_category = f"and parent_category = \'{parent_category}\'"
    
    #androot_category = ""
    #if root_category:
    #    androot_category = f"and root_category = \'{root_category}\'"    

    limitbatch=""
    if batchsize:
        limitbatch = f"limit {batchsize}"


    top_cat_df = pd.DataFrame(columns=['id', 'category', 'rootcategory', 'parentcategory'])
    print('priting top category',file=sys.stderr)
    print(top_cat,file=sys.stderr)
  

    for i in range(len(top_cat)):
        print(i,file=sys.stderr)
        category = top_cat.iloc[i,3]
        print(category,file=sys.stderr)
        params = request.get_json()
        # query = 'SELECT id, category, rootcategory, parentcategory  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) ' \
        #         'and length(category)>1 AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or ' \
        #         '(ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\"" + str(category) + "\" " + " LIMIT " + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' ORDER BY mp.id LIMIT ' + str(batchsize)

        # query = 'SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp' \
        #         ' LEFT JOIN superset_views.Outbound_batches AS ob ON ob.master_id != mp.id WHERE (mp.City= ' + '\''+str(city)+ '\'' + ' AND mp.state= ' + '\''+str(state)+ '\''+ \
        #         ') AND mp.verifiedphone IS NOT NULL AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL AND' \
        #         f' (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND carriertype in ({carriertype}) AND mp.category = '+ '\''+ str(category)+ '\''+ ' LIMIT ' + str(batchsize)
        # limitbatch=""
        # if batchsize:
        #     limitbatch = f"LIMIT {batchsize}"
        #query_top_cat = "SELECT mp.id,mp.category,mp.rootcategory,mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
        #         f"LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id = mp.id) WHERE (ob.id IS NULL) {andcity} {andstate} {andcounty}" \
        #         f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)" \
        #         f"AND (mp.carriertype IN ({carriertype})) AND (mp.rootcategory = \"{root_category}\") ORDER BY mp.id {limitbatch}"
        #                      f"WHERE (mp.id IS not NULL)  " \  
        query_top_cat = "SELECT mp.id, mp.category , mp.rootcategory , mp.parentcategory,mp.VerifiedPhone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                        f"WHERE (mp.id IS not NULL)  " \
                        f"{andcity} {andstate} " \
                        f"AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore !=0 AND mp.ValueScore !=50) " \
                        f"AND length(mp.category)> 1 AND (mp.ContactPhoneStatus IS NULL) " \
                        f"AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL '1' MONTH) " \
                        f"AND (mp.carriertype IN ({carriertype})) AND (mp.category = \'{category}\')  {limitbatch} "
        #                # AND (mp.Category = ob.category)
        print(query_top_cat, file = sys.stderr)
        params = {'city': city, 'state': state, 'county': county, 'carriertype': carriertype, 'limitbatch': limitbatch}
        mp_data = db.session.execute(text(query_top_cat), params)
        mp_data = convert_json(mp_data)
        mp_data = pd.json_normalize(mp_data)

        if isinstance(mp_data, pd.DataFrame):
            if len(mp_data) > 0:
                batchsize = batchsize - len(mp_data)
                temp_df = pd.DataFrame()
                temp_df['id'] = mp_data['id']
                temp_df['category'] = mp_data['category']
                temp_df['rootcategory'] = mp_data['rootcategory']
                temp_df['parentcategory'] = mp_data['parentcategory']
                temp_df['VerifiedPhoneNumber'] = mp_data['VerifiedPhone']
                # print(temp_df,file=sys.stderr)
                top_cat_df = top_cat_df.append(temp_df, ignore_index=True)
                top_cat_df.drop_duplicates(subset=['id'], keep="first", inplace=True)
                # print("random df = "+str(len(random_df))+ " cat = "+str(cat),file=sys.stderr)
                # print(len(random_df),file = sys.stderr)
                del temp_df
                del mp_data
            else:
                pass
        if batchsize == 0:
            break
    # print(top_cat_df, file=sys.stderr)
    top_cat_df['call_type'] = 'Top Category'
    return top_cat_df


def remove_duplicate(topcat, randomcat, hour, day, today, batchID, batchsize, state, city, carrier_type):
    print("I AM At remove_ruplicate", file=sys.stderr)
    topcat = topcat.append(randomcat, ignore_index = True)
    topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
    len_all_records = len(topcat)
    if len_all_records < batchsize:
        while len_all_records < batchsize:
            diff = batchsize - len_all_records
            df = random_records_fun(diff, hour, day, today, batchID, city, state, carrier_type, 0)
            topcat.append(df, ignore_index = True)
            topcat.drop_duplicates(subset=['id'], keep="first", inplace=True)
            len_all_records = len(topcat)
            del df
    else:
        pass
    insert_Temp_Outbound_batches(topcat, hour, day, today, batchID)
    return len(topcat)


def error_code(bat_id, code = 1):
    #params = request.get_json()
    msg = ""
    print("I AM HERE 2", file=sys.stderr)
    if code == -1:
        msg = "Invlid Weekday"
    elif code == -2:
        msg = "Invalid Time"
    elif code == -3:
        msg = "Excluded Time"
    elif code == -4:
        msg = "Error Input"
    elif code == -5:
        msg = "Error Batch Type"
    else:
        pass

    if code <= 0:
        query_code = (f'UPDATE superset_views.batch_scheduling SET status = :msg WHERE BatchID = :bat_id')
        params = {'msg' : msg, 'bat_id': bat_id}
        query_code = text(query_code)
        db.session.execute((query_code), params)
        db.session.commit()
    else:
        query = (f'UPDATE superset_views.batch_scheduling SET status = "closed" WHERE BatchID = :bat_id', params)
        db.session.execute(text(query))
        db.session.commit()


# [{"city":"jammu" ,"state":"JK", "hour":5}, {"city": "ambala", "state" : "haryana", "hour":8}] EXPECTED JSON FORMAT
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/get-batch', methods = ['POST'])
def insert_batch_scheduling():
    db.create_all()
    db.session.execute(f'DELETE FROM superset_views.batch_scheduling') # Delete all the existing rows before insert new requirements
    i=0
    for row in request.json:
        if i==0:
            #print(row, file=sys.stderr)   
            params = request.get_json()
            db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)', params)
    #db.session.execute(f'INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type) VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batch_type)')
            i=1
        else:
            pass

    print("Success")
    db.session.commit()
    print("Failure")
    Batch_scheduling()
    return '200'
    

#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
def Batch_scheduling():
    status = 'open'
    query_batch = f"select * from superset_views.batch_scheduling where status = \'{status}\'"
    #query_batch = ("SELECT * FROM superset_views.batch_scheduling WHERE (status = 'open')")
    #params = {'status': 'open'}
    batch_schedule_data = db.session.execute(text(query_batch))
    #app.logger.info(params)
    batch_schedule_data = convert_json(batch_schedule_data)
    batch_schedule_data = pd.json_normalize(batch_schedule_data)
    len_bat_schedule_data = len(batch_schedule_data)
    print(len_bat_schedule_data, file=sys.stderr)
    if len_bat_schedule_data == 0:
        return "None of the open status available"

    county = batch_schedule_data['County']
    city = batch_schedule_data['City']
    state = batch_schedule_data['State']
    bat_id = batch_schedule_data['BatchID']
    week_day = batch_schedule_data['Day']
    hour = batch_schedule_data['Hour']
    #hour = list(map(int, hour))
    batchsize = batch_schedule_data['Count']
    #batchsize = list(map(int, batchsize))
    random_ness = batch_schedule_data['Randomness']
    #random_ness = list(map(int, random_ness)) #remove this to run
    carrier_type = batch_schedule_data['carriertype']
    batch_type = batch_schedule_data['batch_type']
    #print(city, file=sys.stderr)
    print(batch_type, file=sys.stderr)
    print(len(batch_type), file=sys.stderr)

    result = 0
    i = 0

    for i in range(0, len_bat_schedule_data):
        #print(f"({batch_type[i]})  {str(county[i])}  {str(city[i])} {str(state[i])} {str(int(hour[i]))} "\
        #        f"{str(week_day[i])} {batchsize[i]}", file=sys.stderr)
        code = outbound_batch_parameters(batch_type[i], county[i], city[i], state[i], int(hour[i]), week_day[i], int(batchsize[i]), bat_id[i], carrier_type[i], int(random_ness[i]))
        #error_code(bat_id[i],  code) #uncomment it and run the code
        print(result,file=sys.stderr)
        return str(result)
    return "Done"


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches')
# def outbound_batch_parameters():
def outbound_batch_parameters(batch_type, county, city, state, hour, week_day, batchsize, bat_id, carrier_type,random_ness = 20): #work from here
    # print(f"{city},{state},{hour},{week_day},{batchsize},{bat_id},{carrier_type},{random_ness} ",file=sys.stderr)
    # batch_type = 'notinterested'
    # county = 'Los Angeles'
    # city = 'Los Angeles'
    # state = 'CA'
    # hour = 9
    # week_day = 'Monday'
    # batchsize = 10
    # bat_id = 4
    # carrier_type = 'MIX'
    # random_ness = 20
    print("I am at outbound Batch Parameters API",file=sys.stderr)
    print(type(hour),file=sys.stderr)
    print(hour,file=sys.stderr)
    valid_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
    # week_day = request.args.get('we')
    # hour = int(request.args.get('ho'))
    # batchsize = int(request.args.get('ba'))
    # random_ness = int(request.args.get('rness', default=20, type=int))
    # bat_id = request.args.get('bat_id')
    # random_ness = 20
    # result = time_checker(week_day, hour)
    # if result == 0:
    #     return "ERROR TYPE - EXCLUDED TIME"
    
    week_day = week_day.upper()
    print(week_day, file = sys.stderr)
    print('I am printing batch type:',file=sys.stderr)
    print(batch_type, file = sys.stderr)

    if week_day not in valid_days:
        # return "ERROR: INVALID WEEKDAY", -1
        return -1

    elif hour < 0 or hour > 23:
        # return "ERROR: INVALID TIME ", -2
        return -2
    else:
        res = time_checker(week_day, hour)
        print(res, file = sys.stderr)
        if res == 'No':
            # return "ERROR: EXCLUDED TIME", -3
            return -3
        elif res == -1:
            # return "ERROR: INPUT", -4
            return -4
        else:
            pass
    

    batch_type = str(batch_type).upper()
    print(batch_type, file = sys.stderr)
    today = datetime.datetime.now()

    if batch_type == 'FRESH':
        #pass
        result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
        print(result, file=sys.stderr)

    elif batch_type == 'CALLBACK':
        records = call_back(hour, week_day, today, bat_id, batchsize, city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    elif batch_type == 'INTERESTED':
        records = interested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'NOTINTERESTED':
        records = notinterested(hour, bat_id, week_day, batchsize,  city, state, county)
        # return "Done", records
        return records
    elif batch_type == 'CALLATTEMPTED_NOTCONNECTED':
        records = callattempted_notconnected(hour, week_day,today, bat_id, batchsize,  city, state, county)
        if records == 0:
            # return "NO call back record found", 1
            return 1
        else:
            # return "Done", records
            return records
    else:
        # return "ERROR BATCH TYPE", -5
        return -5

    #result = outBoundBAtch_Fresh(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    #result = outBoundBAtch(county, city, state, week_day, hour, batchsize, bat_id, carrier_type, random_ness)
    print(result, file=sys.stderr)
    return result



#@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/getbatches1')
# def outBoundBAtch_Fresh(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
#def outBoundBAtch():
#def outBoundBAtch(city, state, day, hour, Batchsize):
def outBoundBAtch(county, city, state, day, hour, Batchsize, batchID, carrier_type, random_percent=20):
    print("I am in outBoundBatchAPI for FRESH Batch Type",file=sys.stderr)
    county = 'Los Angeles'
    #city = 'Los Angeles'
    #state = 'CA'
    #hour = 16
    #day = 'saturday'
    #Batchsize = 50
    #batchID = 13
    #random_percent = 20
    county = county
    city = city
    state = state
    hour = hour
    day = day
    Batchsize = Batchsize
    batchID = batchID
    
    print(day,file=sys.stderr)
    print(hour,file=sys.stderr)
    print(city,file=sys.stderr)
    print(batchID,file=sys.stderr)
    print(Batchsize,file=sys.stderr)
    random_percent = 20
    carrier_type = 'wireless'
    print("I am at 3",file=sys.stderr)
    total_records = 0
    finaldf = 0
    records =0
    top_cat_data =0
    top_cat =0
    random_batch = 0
    top_batch =0
    today = datetime.datetime.now()
# ***************** ONE HOUR DF MODULE **********
# HARDRULE Group B
#     onehour_df = onehour_call(Batchsize, city, state, carrier_type) #added the onehour df here
#
#     if isinstance(onehour_df, pd.DataFrame):
#         len_onehour_df = len(onehour_df)
#         if len_onehour_df == Batchsize:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             return records
#         else:
#             records = insert_Temp_Outbound_batches(onehour_df, hour, day, today, batchID)
#             Batchsize = Batchsize - len_onehour_df
#     else:
#         pass

# ***************** ONE HOUR DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
# ***************** CALL BACK DF MODULE **********

    # call_back_records = call_back(Batchsize)
    # if isinstance(call_back_records, pd.DataFrame):
    #     len_call_back_records = len(call_back_records)
    #     if len_call_back_records == Batchsize:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         return records
    #     else:
    #         records = insert_Temp_Outbound_batches(call_back_records, hour, day, today, batchID)
    #         Batchsize = Batchsize - records
    # else:
    #     pass


# ***************** CALL BACK DF MODULE ENDS **********
# __________________________________________________________________________________________________________________
    query = (f"SELECT * FROM Historical_basis WHERE (time_of_day = :time_of_day) AND (weekday = :day) ORDER BY c_time_per_conversion")
            #VALUES (:hour, :day)"), params
    params = {'time_of_day': hour, "day" : day}
    #query = f'SELECT * FROM Historical_basis where time_of_day = {hour} and weekday = \'{day}\' ORDER BY c_time_per_conversion'
    
    historical_basis = db.session.execute(text(query), params)
    historical_basis = convert_json(historical_basis)
    historical_basis = pd.json_normalize(historical_basis)

    temp = 0
    skip = 0
    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    finaldf = pd.DataFrame()
    records = 0

    # TEST CASE 1: when we dont have any category in particular hour and random_percent converted to 100%
    if isinstance(historical_basis, pd.DataFrame):
        if len(historical_basis) == 0:
            records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
            print("history is zero so random is = "+str(records), file=sys.stderr)
            return records
        else:
            pass
    else:
        pass

    # TEST CASE 2: we dialed categories but have zero interested  Check?
    all_categories = list(historical_basis['category'].unique())  # all categories in the historical data
    top_cat_data = historical_basis[historical_basis['c_time_per_conversion'] > 0]  # selecting only interested records

    if len(top_cat_data) == 0:  # if all dialed categories has zero interested
        records = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        print("Has history but top cat is zero so random is = "+str(records), file=sys.stderr)
        del top_cat_data
        return records
    else:
        pass

    top_cat_data = top_cat_data.sort_values(by=['c_time_per_conversion'])
    #print('Printing top cat data',file=sys.stderr)
    #print(top_cat_data,file=sys.stderr)
    #category = top_cat_data['category']
    #parent_category = top_cat_data['parent_category']
    #root_category = top_cat_data['root_category']
    #print(parent_category,file=sys.stderr)
    #print(root_category,file=sys.stderr)
    #top_cat = list(top_cat_data['category'].unique())
    #print(top_cat)

    random_batch = round((Batchsize * random_percent)/100)
    top_batch = Batchsize - random_batch

    print("BATCHSIZE = "+str(Batchsize),file=sys.stderr)
    print("random % = "+str(random_percent),file=sys.stderr)
    print("random records = "+str(random_batch),file=sys.stderr)
    print("top cat = "+str(top_batch), file=sys.stderr)

    print(top_cat_data,file=sys.stderr)

    #temp_df = top_cat_records(county, city, state, Batchsize, top_cat, carrier_type) #return records from top category
    temp_df = top_cat_records(county, city, state, Batchsize, top_cat_data, carrier_type) #return records from top category
    # return str(temp_df)

    if isinstance(temp_df, pd.DataFrame):  # do we have records from top categories if yes then
        if len(temp_df) >= top_batch:
            print("I AM HERE 5", file=sys.stderr)
            print(f"top cat has data length = {len(temp_df)}" , file=sys.stderr)
            print(f"batch size is  = {Batchsize}" , file=sys.stderr)
            # temp_df.drop(temp_df.tail(random_records).index,inplace=True)
            temp_df = temp_df[0:top_batch]
            print(temp_df, file = sys.stderr)
            print(f"data after cut  = {len(temp_df)}", file=sys.stderr)

            #top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type, 0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            totalrecords = temp_df.append(random_records, ignore_index=True)
            top_records = insert_Temp_Outbound_batches(totalrecords, hour, day, today, batchID)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            del temp_df
            return (totalrecords)
            # random_records = random_records[0:random]
            # temp_df.append(random_records, ignore_index=True)
        else:
            ret_records = len(temp_df)
            random_batch = Batchsize - ret_records
            # top_records = insert_Temp_Outbound_batches(temp_df, hour, day, today, batchID)
            random_records = random_records_fun(random_batch, hour, day, today, batchID, county, city, state, carrier_type,0)
            totalrecords = remove_duplicate(temp_df, random_records, hour, day, today, batchID, Batchsize, state, city, carrier_type)
            del finaldf
            del records
            del top_cat_data
            del top_cat
            del random_batch
            del top_batch
            return str(totalrecords)
    else:
        df = random_records_fun(Batchsize, hour, day, today, batchID, county, city, state, carrier_type)
        records = len(df)
        return records


def insert_Temp_Outbound_batches(final, hour, day, today, batchID):
    params = request.get_json()
    # print("Final DF at Insert", file=sys.stderr)
    # print(f"Inside insert  and batchid is = {batchID}", file=sys.stderr)
    # s = ['id', 'call_type']
    # print(final[s], file=sys.stderr)
    rows = list(final.shape)
    print(rows,file=sys.stderr)
    rows = rows[0]
    total_records = rows
    #db.session.execute(f'DELETE FROM superset_views.Outbound_batches') 
    for row in range(0, rows):
        print(row, file=sys.stderr)
        
        mid = final.iloc[row]['id']
        cate_gory = final.iloc[row]['category']
        parent_category = final.iloc[row]['parentcategory']
        root_category = final.iloc[row]['rootcategory']
        call_type = final.iloc[row]['call_type']
        phone_number = final.iloc[row]['VerifiedPhoneNumber']

        params = request.get_json()
        # db.session.execute(text((
        #                          'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id )'
        #                          ' values (' + '\'' + str(hour) + '\'' + ',' + '\'' + str(
        #                          day) + '\'' + ',' + '\'' + str(cate_gory) + '\'' + ',' + '\'' + str(
        #                          parent_category) + '\'' + ',' + '\'' + str(
        #                          root_category) + '\'' + ',' + '\'' + str(mid) + '\'' + ',' + '\'' + str(
        #                          today) + '\'' + ',' + '\'' + str(batchID) + '\'' + ')')))
        
        query = 'INSERT into Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type,VerifiedPhoneNumber) VALUES ( :hour, :week_day, :cate_gory, :parent_category, :root_category, :mid, :today, :batchID, :call_type, :phone_number)'
        params = {'hour': hour, 'week_day' : day, 'cate_gory' : cate_gory, 'parent_category': parent_category, 'root_category': root_category, 'mid': mid, 'today': today, 'batchID': batchID, 'call_type': call_type, 'phone_number':phone_number}
        db.session.execute(text(query), params)
        #print(query, file = sys.stderr)
        
        #db.session.execute(text(
        #        'INSERT into Temp_Outbound_batches(hour, week_day, category, parent_category, root_category, master_id, Batch_creation_date, Batch_id, batch_type) ' \
        #        f'values ( {hour} , \'{day}\', \'{cate_gory}\', \'{parent_category}\', \'{root_category}\', {mid}, \'{today}\', {batchID} , \'{call_type}\')'))

        db.session.commit()
    print("i am at insert its returning total_records = "+str(total_records),file=sys.stderr)
    return total_records


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/testingweb1')
# def insert_check():
#     row = pd.DataFrame()
#     city         'Los Angeles'
#     state       : 'CA'
#     batchid     : 15
#     day         : 'Wedneday'
#     hour        : 'NULL'
#     count       : 100
#     randomness  : 15
#     carriertype : 'Mix'
#     status      : 'open'
#     batchtype   : 'Fresh'
#    # query = (f'INSERT into superset_views.batch_scheduling(city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)'
#    #            f'values ({city},{state},{batchid},{day},{hour},{count},{randomness}, {carriertype},{status}, {batchtype})')
#     query = ('INSERT into superset_views.batch_scheduling (city, state, batchid, day, hour, count, randomness, carriertype , status, batch_type)' \
#                         'VALUES ( :city, :state, :batchid, :day, :hour, :count, :randomness, :carriertype, :status, :batchtype) ', params)
#     db.session.execute(text(query))
#     db.session.commit()
#     return "Inserted into batch scheduling"

def outbound_Call_df(category_List, batchsize, city, state):
    final_df = pd.DataFrame()
    final_id = []
    flag = 1
    counter = 0
    non_record = 0
    for category in category_List:
        # query = 'SELECT id, rootcategory, parentcategory,  category, phone  from `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider ' \
        #         'WHERE (City = "Los Angeles" and state = "CA" ) and verifiedphone IS NOT NULL and (ValueScore != 0 and ValueScore != 50) and length(category)>1 ' \
        #         'AND ((ContactPhoneStatus IS NULL  and lastcontactDate IS NULL) or (ContactPhoneStatus is null and lastcontactDate < now() - interval 1 month)) ' \
        #         'AND category = ' + "\'" + str(category) + "\' " + "  LIMIT " + str(batchsize)

        query = "SELECT mp.id, mp.category, mp.rootcategory, mp.parentcategory FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider AS mp " \
                "LEFT JOIN superset_views.Outbound_batches AS ob ON (ob.master_id != mp.id) WHERE ((mp.City= :city) AND (mp.state= :state)) " \
                "AND (mp.verifiedphone IS NOT NULL) AND (mp.ValueScore != 0 AND mp.ValueScore != 50) AND length(mp.category)> 1 " \
                "AND ((mp.ContactPhoneStatus IS NULL) AND (mp.lastcontactDate IS NULL OR mp.lastcontactDate< now()-INTERVAL 1 MONTH)) AND (mp.category = :category) " \
                "ORDER BY mp.id LIMIT ( :batchsize)"

        category_wise_data = db.session.execute(text(query))
        category_wise_data = convert_json(category_wise_data)
        category_wise_data = pd.json_normalize(category_wise_data)

        temp_df = pd.DataFrame()

        counter = counter + 1
        id_list = pd.DataFrame()

        if len(category_wise_data) > 0:
            # print(category+ " =  " + str(len(category_wise_data))+"in side Batchsize = " + str(batchsize) , file=sys.stderr)
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
                del temp_df
                del category_wise_data
        else:
            pass
        if flag == 0 or batchsize == 0:
            break

    if non_record == 0:
        return -1
    else:
        final_df = final_df[['id', 'category', 'rootcategory', 'parentcategory']]
        print("Final Df = " + str(len(final_df)) + " Batchsize = " + str(batchsize) + " Counter = " + str(counter),
              file=sys.stderr)
        return final_df


def category_checker(table_name, P_category, sub_category, category):
    # query_city = "select is_excluded from " + table_name + " where parent_category = " + "\"" + P_category +\
    #              "\"" + " and sub_category = " + "\"" + sub_category + "\"" + " and category = " + "\"" + category + "\""
    query_city = " SELECT is_excluded FROM `sumithapauroramysql20181211-cluster-LotusDirectory`." + table_name + " WHERE keyword = " + "\"" + category + "\" "
    cate_query = (text(query_city))
    cate_query = db.session.execute(cate_query)
    result = convert_json(cate_query)
    if len(result) > 0:
        status = [f['is_excluded'] for f in result]
        status = status[0]
        return status
    else:
        return 0

def convert_json(data):
    userList = []
    for u in data:
        userList.append(dict(u))
    return userList


def category_list(state, city, week_day, hour, call_category_raw):
    final_category_list = []
    cat_dict = {}
    call_category_raw = call_category_raw[call_category_raw['state'] == state]  # Select the state only
    call_category_raw = call_category_raw[
    call_category_raw['city'] == city]  # Select the city out of selected states only
    hourly_data = call_category_raw[call_category_raw['day'] == week_day]
    hourly_data = hourly_data[hourly_data['hour'] == hour]
    categories = list(hourly_data['category'].unique())  # unique categories in the selected data
    excl_cat = []
    for category in categories:  # searching the unique categories into the excluded cat table
        flag = category_checker("excluded_cats", "X", "Y", category)
        if flag == 1:
            excl_cat.append(category)
    for excl in excl_cat:
        categories.remove(excl)
    for category in categories:
        cat_data = hourly_data[hourly_data['category'] == category]
        interested = len(cat_data[cat_data['status'] == 'Interested'])
        time_spent_category = cat_data['timediff'].sum()
        if interested > 0:
            per_int_cate = round(time_spent_category / interested)
            cat_dict[category] = per_int_cate
    temp = sorted(cat_dict.items(), key=lambda x: x[1], reverse=False)

    for item in temp:
        final_category_list.append(item[0])

    if len(final_category_list) == 0:
        return 0
    else:
        return final_category_list


def final_list(category_LIST, state, city, batchsize, master_provider_data):
    final_id = []
    flag = 1
    temp_df = pd.DataFrame()
    final_df = pd.DataFrame()
    non_record = 0

    master_provider_data = master_provider_data[master_provider_data['state'] == state]  # Select the state only
    master_provider_data = master_provider_data[
        master_provider_data['city'] == city]  # Select the city out of selected states only
    master_provider_data['category'] = master_provider_data[
        'category'].str.upper()  # converting the column into capital letter
    id_list = pd.DataFrame()
    for category in category_LIST:
        category = (str(category)).upper()
        # category_wise_data = master_provider_data[master_provider_data['root_categories'] == root_category]
        # category_wise_data = master_provider_data[master_provider_data['parent_categories'] == parent_category]
        category_wise_data = master_provider_data[master_provider_data['category'] == category]  # category_wise_data
        category_wise_data.drop_duplicates(subset=['phone'], keep="first", inplace=True)
        category_wise_data.drop_duplicates(subset=['id'], keep="first", inplace=True)
        if len(category_wise_data) > 1:
            non_record = 1
            id_list = category_wise_data['id']
            temp_df['id'] = category_wise_data['id']
            temp_df['name'] = category_wise_data['name']
            temp_df['category'] = category_wise_data['category']
            temp_df['rootcategory'] = category_wise_data['rootcategory']
            temp_df['parentcategory'] = category_wise_data['parentcategory']
            id_list = id_list.to_list()
            current_batch_size = len(id_list)
            if current_batch_size > batchsize:
                id_list = id_list[0:batchsize]
                temp_df = temp_df[0:batchsize]
                final_df = final_df.append(temp_df, ignore_index=True)
                final_id.extend(id_list)
                flag = 0
            else:
                final_id.extend(id_list)
                final_df = final_df.append(temp_df, ignore_index=True)
                batchsize = batchsize - current_batch_size
            if flag == 0:
                break

    if non_record == 0:
        return final_df.empty
    else:
        final_df = final_df[['id', 'name', 'rootcategory', 'parentcategory', 'category']]
        return final_df


# ************************ passing data to table superset_views.historical_basis
@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/cons_hist')
def consolidate_history():
    params = request.get_json()
    #{
    i = 0
    temp_df = pd.DataFrame([], columns=(
                     'time_of_day', 'weekday', 'category', 'parent_category', 'root_category', 'time_per_conversion', 'date'))
    today = datetime.datetime.now()
    #}
    app.logger.info(params)
    category_intermediate_table = db.session.execute(text(
                'SELECT Date, Hour, DayofWeek, Category, ParentCategory, RootCategory, TimeSpent, TotalConversion FROM hour_category_intermediate WHERE TotalConversion = 0'))
    
    category_intermediate_table = convert_json(category_intermediate_table)
    category_intermediate_table = pd.json_normalize(category_intermediate_table)
    week_days = category_intermediate_table['DayofWeek'].unique()
    week_days.sort()
    for week_day in week_days:
        week_wise_data = category_intermediate_table[category_intermediate_table['DayofWeek'] == week_day]
        hours = week_wise_data['Hour'].unique()
        for hour in hours:
            hour_wise_data = week_wise_data[week_wise_data['Hour'] == hour]
            # root_categories = hour_wise_data['RootCategory'].unique()
            # for root_category in root_categories:
            #     root_category_data = hour_wise_data[hour_wise_data['RootCategory'] == root_category]
            #     parent_categories = root_category_data['ParentCategory'].unique()
            #     for parent_category in parent_categories:
            #         category_wise_data = root_category_data[root_category_data['ParentCategory'] == parent_category]
            categories = hour_wise_data['Category'].unique()
            for category in categories:
                i = i + 1
                category_data = hour_wise_data[hour_wise_data['Category'] == category]
                parent_category = category_data.iloc[0]['ParentCategory']
                root_category = category_data.iloc[0]['RootCategory']
                total_time_spent = category_data['TimeSpent'].sum()
                total_conversion = category_data['TotalConversion'].sum()

                if total_time_spent > 0 and total_conversion > 0:
                    conversion_ratio = total_time_spent / total_conversion
                else:
                    conversion_ratio = 0
                # conversion_ratio = 0
                category = category.replace('\'', '')
                parent_category = parent_category.replace('\'', '')
                root_category = root_category.replace('\'', '')
                # temp = {'time_of_day':hour, 'weekday': week_day, 'category': category,'parent_category': parent_category,'root_category':root_category, 'conversion_ratio': str(conversion_ratio) , 'date': str(today)}
                # temp_df = temp_df.append(temp, ignore_index=True)
                db.session.execute('INSERT into Historical_basis (time_of_day, weekday, category, parent_category, root_category, time_per_conversion, date)' \
                                    'VALUES ( :time_of_day, weekday, :category, :parent_category, :root_category, :time_per_conversion, :date) ', params)
                db.session.commit()
                # insert_string = "insert into historical_basis values" + str(hour) + str(week_day) + category + " \
                #                 "parent_category + root_category + str(conversion_ratio) + str(today)
                # s = [hour , week_day, category, parent_category, root_category, conversion_ratio, today]
                # df.loc[len(df.index)] = s

    return str((temp_df.shape))


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/param')
# def with_parameters():
#     #params = {
#     #     state = request.args.get('st')
#     #     city = request.args.get('ci')
#     #     week_day = int(request.args.get('we'))
#     #     hour = int(request.args.get('ho'))
#     #     batchsize = int(request.args.get('ba'))
#     # }
#     result = users1(state, city, week_day, hour, batchsize)
#     return result


# def users1(state, city, week_day, hour, batchsize):
#     # *********** TIME CHECKER Starts ********
#     status_time_checker = time_checker(week_day, hour)
#     if status_time_checker == 0:
#         return "INVALID TIME AND EXIT"
#     # *********** TIME CHECKER ENDS ********

#     # -----------------------------------------------------------------------------------------------------------
#     # *********** CITY CHECKER Starts ******** #
#     table_name = "Inclusive_cities"
#     status_city_checker = city_checker(table_name, state, city)
#     if status_city_checker == -1:
#         return "INVALID CITY AND EXIT"
#     else:
#         print(str(status_city_checker), file=sys.stderr)
#     # *********** CITY CHECKER ENDs ********
#     # -----------------------------------------------------------------------------------------------------------
#     master_provider_data = db.session.execute(text(
#         'SELECT name, id, rootcategory, parentcategory,  category, city, state FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE ((City = :city) AND (state = :state))'))
#     master_provider_data = convert_json(master_provider_data)
#     master_provider_data = pd.json_normalize(master_provider_data)
 
#     call_category_raw = db.session.execute(text(
#         'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE ((City = :city) AND (state = :state))'))
#     call_category_raw = convert_json(call_category_raw)
#     call_category_raw = pd.json_normalize(call_category_raw) 
#     call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
#     call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
#     call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
#     call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
#     category_LIST = category_list(state, city, week_day, hour, call_category_raw)
#     if len(category_LIST) == 0:
#         return "Non of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(
#             week_day)
#     final = final_list(category_LIST, state, city, batchsize, master_provider_data)
#     # final = final.to_dict('records')
#     if final.empty:
#         return "Final DF is empty"
#     else:
#         rows = list(final.shape)
#         rows = rows[0]
#         for row in range(0, rows):
#             mid = final.iloc[row]['id']
#             name = final.iloc[row]['name']
#             cate_gory = final.iloc[row]['category']
#             parent_category = final.iloc[row]['parentcategory']
#             root_category = final.iloc[row]['rootcategory']
#             db.session.execute(
#                 text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \ 
#                       ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
#                       ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
#                       ' root_category) + '\'' + ')')))                       
#             #db.session.execute('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category)'
#             #                      'VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
#             db.session.commit()
#         final = final.to_dict('records')
#     print(category_LIST, file=sys.stderr)
#     return jsonify(final)


@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/data')
def users():
    params = request.get_json()
    # Initial input variable
    start_time = time.time()
    state = "CA"
    city = "Los Angeles"
    week_day = 5
    hour = 19
    batchsize = 100
    # -----------------------------------------------------------------------------------------------------
    # *********** TIME CHECKER Starts ********
    status_time_checker = time_checker(week_day, hour)
    if status_time_checker == 0:
        return "INVALID TIME AND EXIT"
    # *********** TIME CHECKER ENDS ********

    # -----------------------------------------------------------------------------------------------------------
    # *********** CITY CHECKER Starts ******** #
    table_name = "Inclusive_cities"
    status_city_checker = city_checker(table_name, state, city)
    if status_city_checker == -1:
        return "INVALID CITY AND EXIT"
    else:
        print(str(status_city_checker), file=sys.stderr)
    # *********** CITY CHECKER ENDs ********
    # -----------------------------------------------------------------------------------------------------------
    master_provider_data = db.session.execute(text(
        'SELECT name, id, rootcategory, parentcategory, category, city, state, phone FROM `sumithapauroramysql20181211-cluster-LotusDirectory`.MasterProvider WHERE City = "Los Angeles" AND state = "CA"'))
    master_provider_data = convert_json(master_provider_data)
    master_provider_data = pd.json_normalize(master_provider_data)

    call_category_raw = db.session.execute(text(
        'SELECT timediff, status, category, city, state, creationtime FROM call_category_raw WHERE City = "Los Angeles" AND state = "CA"'))
    
    call_category_raw = convert_json(call_category_raw)
    call_category_raw = pd.json_normalize(call_category_raw)
    call_category_raw['creationtime'] = (call_category_raw['creationtime'].astype('datetime64[ns]'))
    call_category_raw['hour'] = call_category_raw.creationtime.dt.hour
    call_category_raw['day'] = call_category_raw['creationtime'].dt.dayofweek
    call_category_raw.dropna(subset=['creationtime', 'hour', 'day', 'category', 'status', 'timediff'], inplace=True)
    category_LIST = category_list(state, city, week_day, hour, call_category_raw)
    if len(category_LIST) == 0:
        return "None of the Category found in " + state + " " + city + " hour " + str(hour) + " Week day " + str(week_day)

    # try:
    #     if len(category_LIST) == 0:
    #         return "Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    #     else:
    #         pass
    # except:
    #     return "not a valid cat. Non of the Category found in "+state + " "+city + " hour " + str(hour) + " Week day " + str(week_day)
    
    final = final_list(category_LIST, state, city, batchsize, master_provider_data)
    if final.empty:
        return "Final List is empty"
    else:
        rows = list(final.shape)
        rows = rows[0]
        for row in range(0, rows):
            mid = final.iloc[row]['id']
            name = final.iloc[row]['name']
            cate_gory = final.iloc[row]['category']
            parent_category = final.iloc[row]['parentcategory']
            root_category = final.iloc[row]['rootcategory']
            # db.session.execute(
            #     text(('INSERT into exclusion_output (masterProv_id , name, category ,parent_category ,root_category )' \
            #           ' values (' + '\'' + str(mid) + '\'' + ',' + '\'' + str(name) + '\'' + ',' + '\'' + str( ' \
            #           ' cate_gory) + '\'' + ',' + '\'' + str(parent_category) + '\'' + ',' + '\'' + str( ' \
            #           ' root_category) + '\'' + ')')))
            db.session.execute('INSERT into exclusion_output (masterProv_id , name, category, parent_category,root_category )  VALUES ( :mid, :name, :cate_gory, :parent_category, :root_category) ', params)
            db.session.commit()
        final = final.to_dict('records')
    return jsonify(final)


# @app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/DelBatch')  # Working Fine
def del_eteBatch(batchid):
    params = {
    "batchid" : request.json['batchid']
    }
    app.logger.info(params)
    db.session.execute('DELETE FROM superset_views.Outbound_batches WHERE Batch_id = :batchid')
    db.session.commit()
    return '200'

    
    # # batchid = int(request.args.get('bid'))
    # # batch_Del = db.session.execute(
    # #     text('select * from superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # # batch_Del = convert_json(batch_Del)
    # # if (len(batch_Del)) > 0:
    # #     db.session.execute(text('DELETE FROM superset_views.Outbound_batches where Batch_id =  ' + str(batchid)))
    # #     result = db.session.commit()
    # #     return '200'
    # #     # return " ALL RECORDS ARE DELETED FROM TABLE OUTBOUNT_BATCH WITH THE BATCH ID : " + str(batchid)
    # else:
    #     return 'Batch id is not found'
    #     # return "ERROR INPUT: BATCH ID = " + str(batchid)

@app.route('/' + os.environ['APP_NAME'] + '/System/ServerSide/fillTime_rules')
def time_fill():
    params = request.get_json()
    #{
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    #"t"     : request.json[0 - 23],
    #"status": request.json['Yes', 'No']
    #}
    app.logger.info(params)
    for day in days:
        for t in range(0, 24):
            if t > 7 and t < 19:
                status = "Yes"
            else:
                status = "No"
            db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :days, :t, :status) ', params)
    db.session.commit()
    return '200'

    for t in range(0, 24):
        db.session.execute('INSERT into Time_rules (Weekday, Time, Status) VALUES ( :Sunday, :t, :No) ', params)
    db.session.commit()
    return '200'

    return "Time_rules is updated"


if __name__ == '__main__':
    app.run
 


if __name__ == '__main__':
    app.run
 